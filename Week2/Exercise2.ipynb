{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, build a code for a perceptron(i.e. a single neuron and no hidden layers) and build a AND gate using it.\n",
    "2. Now, try to build a XOR gate using a perceptron and share your results with us.\n",
    "3. Implement a XOR gate again, this time you can use a single hidden layer.\n",
    "4. Build a full adder using the perceptron you have built\n",
    "5. Combine the adders into a ripple carry adder\n",
    "\n",
    "IMPortant: Do not use scikit learn or keras or any other libraries. Implement the codes from scratch using numpy.\n",
    "Implement seperate functions such as initialization, forward propagation, cost calculation and back propagation and then compile all of it in a class/function and test your neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x, w, b) :\n",
    "    y = np.matmul(np.transpose(w),x) + b\n",
    "    a = np.sigmoid(y)\n",
    "    return y, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_bin(x, w, b) :\n",
    "    threshold = 0.5\n",
    "    if (perceptron[1] > threshold) : return 1\n",
    "    else : return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_calculation(y_hat, y):\n",
    "        m = len(y)\n",
    "        cost = (1 / (2 * m)) * (np.sum((y_hat - y) ** 2))\n",
    "        return cost\n",
    "\n",
    "def sigmoid_derivative(y):\n",
    "        return np.sigmoid(y) * (1 - np.sigmoid(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_0(object):                    # No hidden layer\n",
    "    def __init__(self, inputs, outputs) :\n",
    "        self.weights = np.random.rand(1, inputs.shape[1]) * 0.01\n",
    "        self.bias = np.random.rand(1) * 0.01\n",
    "        \n",
    "    def forward_propagation(self, x):\n",
    "        return perceptron(x, self.weights, self.bias)\n",
    "    \n",
    "    def back_propagation(self, inputs, outputs):\n",
    "        num_samples = inputs.shape[0]\n",
    "        \n",
    "        for itr in range(100):\n",
    "            \n",
    "            for i in range(num_samples):\n",
    "                x = inputs[i].reshape(-1, 1)  # Input as column vector\n",
    "                y = outputs[i]                # The desired output\n",
    "\n",
    "                z, y_hat = self.forward_propagation(x)\n",
    "\n",
    "                # delL/delz (= dz) = delL/delb\n",
    "                dJ_dz = (y_hat - y) * sigmoid_derivative(z)\n",
    "                dJ_dw = np.dot(dJ_dz, x.T)\n",
    "                dJ_db = dJ_dz\n",
    "\n",
    "                alpha = 0.1\n",
    "\n",
    "                self.weights -= alpha * dJ_dw\n",
    "                self.bias -= alpha * dJ_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_1(object):                    # 1 hidden layer\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size) :\n",
    "        self.weights1 = np.random.rand(hidden_layer_size, input_size) * 0.01\n",
    "        self.bias1 = np.random.rand(hidden_layer_size, 1) * 0.01\n",
    "        self.weights2 = np.random.rand(output_size, hidden_layer_size) * 0.01\n",
    "        self.bias2 = np.random.rand(output_size, 1) * 0.01\n",
    "\n",
    "\n",
    "    def forward_propagation(self, x):\n",
    "        z1, a1 = perceptron(x, self.weights1, self.bias1)\n",
    "        z2, a2 = perceptron(a1, self.weights2, self.bias2)\n",
    "        return z1, a1, z2, a2\n",
    "    \n",
    "\n",
    "    def back_propagation(self, inputs, outputs):\n",
    "        for itr in range(100):\n",
    "            \n",
    "            for i in range(inputs.shape[0]):\n",
    "                x = inputs[i].reshape(-1, 1)  # Input as column vector\n",
    "                y = outputs[i].reshape(-1, 1) # The desired output\n",
    "\n",
    "                z1, a1, z2, y_hat = self.forward_propagation(x)\n",
    "\n",
    "                # dL/dz_2 (= dz_2) = dL/db_2\n",
    "                dJ_dz_2 = (y_hat - y) * sigmoid_derivative(z2)\n",
    "                dJ_dw_2 = np.dot(dJ_dz_2, a1.T)\n",
    "                dJ_db_2 = dJ_dz_2\n",
    "\n",
    "                dJ_dz_1 = np.dot(self.weights1, dJ_dz_2) * sigmoid_derivative(z1)\n",
    "                dJ_dw_1 = np.dot(dJ_dz_1, x.T)\n",
    "                dJ_db_1 = dJ_dz_1\n",
    "\n",
    "                alpha = 0.1\n",
    "\n",
    "                self.weights2 -= alpha * dJ_dw_2\n",
    "                self.bias2 -= alpha * dJ_db_2\n",
    "                self.weights1 -= alpha * dJ_dw_1\n",
    "                self.bias1 -= alpha * dJ_db_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
